---
title: "02a_EMA_idio_centrality"
output: html_notebook
---

# Centrality tables
```{r set up}
path = "Paper_res/Imputed_results"
```

```{r Means strength centrality top 6}
# Top 6 - means
files_to_read = list.files(
  path = path,       
  pattern = "_centr_means_imputed\\.csv$", 
  recursive = TRUE,         
  full.names = TRUE          
)

# make list of participant dataframes
data_lst_means = lapply(files_to_read, read.csv) 

# combine all dataframes into one
combined_data_means <- do.call(rbind, data_lst_means)

# Confirm categories
unique(combined_data_means$measure)

# Table for Strengths
strength_counts <- table(combined_data_means$node[combined_data_means$measure == "Strength"])
(strength_df <- as.data.frame(strength_counts))
# write.csv(strength_df, "Paper_res/New_tables/Top_6_centrality_imputed_means.csv")
```

```{r Means strength centrality top 2}
# Table with how many times each ED features was (1) strongest and (2) second-to-strongest in the contemporaneous means network

top_strength_nodes <- c()      # For strongest
second_strength_nodes <- c()   # For second strongest

for (file in data_lst_means) {
  strength_data <- file[file$measure == "Strength", ]
  strength_sorted <- strength_data[order(-strength_data$value), ]
  top_strength_nodes <- c(top_strength_nodes, strength_sorted$node[1])
  if (nrow(strength_sorted) >= 2) {
    second_strength_nodes <- c(second_strength_nodes, strength_sorted$node[2])
  }
}

# Count frequencies
strength_top_counts <- as.data.frame(table(top_strength_nodes))
second_strength_counts <- as.data.frame(table(second_strength_nodes))

colnames(strength_top_counts) <- c("Node", "Strength_Top")
colnames(second_strength_counts) <- c("Node", "Strength_Second")

# Combine first and second-most central
combined_strength_counts <- merge(strength_top_counts, second_strength_counts, by = "Node", all = TRUE)

combined_strength_counts[is.na(combined_strength_counts)] <- 0

print(combined_strength_counts)
```

```{r SDs strength centrality top 6}
# Top 6 - SDs
files_to_read = list.files(
  path = path,       
  pattern = "_centr_sd_imputed\\.csv$", 
  recursive = TRUE,          
  full.names = TRUE         
)

data_lst_sds = lapply(files_to_read, read.csv)  

combined_data_sds <- do.call(rbind, data_lst_sds)

# Table for Strengths
strength_counts <- table(combined_data_sds$node[combined_data_sds$measure == "Strength"])
(strength_df <- as.data.frame(strength_counts))

# write.csv(strength_df, "Paper_res/New_tables/Top_6_centrality_imputed_sd.csv")
```

```{r SDs strength centrality top 2}
# Table with how many times each ED features was (1) strongest and (2) second-to-strongest in the contemporaneous variability network

top_strength_nodes <- c()      # For strongest
second_strength_nodes <- c()   # For second strongest

for (file in data_lst_sds) {
  strength_data <- file[file$measure == "Strength", ]
  strength_sorted <- strength_data[order(-strength_data$value), ]
  top_strength_nodes <- c(top_strength_nodes, strength_sorted$node[1])
  if (nrow(strength_sorted) >= 2) {
    second_strength_nodes <- c(second_strength_nodes, strength_sorted$node[2])
  }
}

# Count frequencies
strength_top_counts <- as.data.frame(table(top_strength_nodes))
second_strength_counts <- as.data.frame(table(second_strength_nodes))

colnames(strength_top_counts) <- c("Node", "Strength_Top")
colnames(second_strength_counts) <- c("Node", "Strength_Second")

# Combine first and second-most central
combined_strength_counts <- merge(strength_top_counts, second_strength_counts, by = "Node", all = TRUE)

combined_strength_counts[is.na(combined_strength_counts)] <- 0

# Add percentages
total_datasets <- 31

combined_strength_counts$Strength_Top <- paste0(combined_strength_counts$Strength_Top, " (", 
                                                sprintf("%.2f", 
                                                        (combined_strength_counts$Strength_Top / total_datasets) * 100), "%)")
combined_strength_counts$Strength_Second <- paste0(combined_strength_counts$Strength_Second, " (", 
                                                   sprintf("%.2f", 
                                                           (combined_strength_counts$Strength_Second / total_datasets) * 100), "%)")

print(combined_strength_counts)

write.csv(combined_strength_counts, "Paper_res/New_tables/Top_2_strength_imputed_sds.csv")
```

```{r Means OutStrength and InStrength}

top_outstrength_nodes <- c()      
second_outstrength_nodes <- c()   

top_instrength_nodes <- c()      
second_instrength_nodes <- c()    

total_datasets <- length(data_lst_means)

for (file in data_lst_means) {
  outstrength_data <- file[file$measure == "OutStrength", ]
  
  outstrength_sorted <- outstrength_data[order(-outstrength_data$value), ]
  
  top_outstrength_nodes <- c(top_outstrength_nodes, outstrength_sorted$node[1])
  if (nrow(outstrength_sorted) >= 2) {
    second_outstrength_nodes <- c(second_outstrength_nodes, outstrength_sorted$node[2])
  }
  
  instrength_data <- file[file$measure == "InStrength", ]
  
  instrength_sorted <- instrength_data[order(-instrength_data$value), ]
  
  top_instrength_nodes <- c(top_instrength_nodes, instrength_sorted$node[1])
  if (nrow(instrength_sorted) >= 2) {
    second_instrength_nodes <- c(second_instrength_nodes, instrength_sorted$node[2])
  }
}

# Count the frequency of the strongest and the second strongest
outstrength_top_counts <- as.data.frame(table(top_outstrength_nodes))
second_outstrength_counts <- as.data.frame(table(second_outstrength_nodes))

instrength_top_counts <- as.data.frame(table(top_instrength_nodes))
second_instrength_counts <- as.data.frame(table(second_instrength_nodes))

colnames(outstrength_top_counts) <- c("Node", "OutStrength_Top_mean")
colnames(second_outstrength_counts) <- c("Node", "OutStrength_Second_mean")

colnames(instrength_top_counts) <- c("Node", "InStrength_Top_mean")
colnames(second_instrength_counts) <- c("Node", "InStrength_Second_mean")

# Combine OutStrength and InStrength
combined_outstrength_counts <- merge(outstrength_top_counts, second_outstrength_counts, by = "Node", all = TRUE)
combined_instrength_counts <- merge(instrength_top_counts, second_instrength_counts, by = "Node", all = TRUE)

# Combine OutStrength and InStrength into one table
combined_strength_counts_means <- merge(combined_outstrength_counts, combined_instrength_counts, by = "Node", all = TRUE)

combined_strength_counts_means[is.na(combined_strength_counts_means)] <- 0

# Add percentages 
combined_strength_counts_means$OutStrength_Top <- paste0(combined_strength_counts_means$OutStrength_Top, " (", 
                                                     sprintf("%.2f", (combined_strength_counts_means$OutStrength_Top / total_datasets) * 100), "%)")
combined_strength_counts_means$OutStrength_Second <- paste0(combined_strength_counts_means$OutStrength_Second, " (", 
                                                        sprintf("%.2f", (combined_strength_counts_means$OutStrength_Second / total_datasets) * 100), "%)")

combined_strength_counts_means$InStrength_Top <- paste0(combined_strength_counts_means$InStrength_Top, " (", 
                                                    sprintf("%.2f", (combined_strength_counts_means$InStrength_Top / total_datasets) * 100), "%)")
combined_strength_counts_means$InStrength_Second <- paste0(combined_strength_counts_means$InStrength_Second, " (", 
                                                       sprintf("%.2f", (combined_strength_counts_means$InStrength_Second / total_datasets) * 100), "%)")

print(combined_strength_counts_means)

write.csv(combined_strength_counts_means, "Paper_res/New_tables/Top_2_out_and_in_strength_means.csv")
```

```{r SDs OutStrength and InStrength}

top_outstrength_nodes <- c()      
second_outstrength_nodes <- c()   

top_instrength_nodes <- c()      
second_instrength_nodes <- c()    

total_datasets <- length(data_lst_sds)

for (file in data_lst_sds) {
  outstrength_data <- file[file$measure == "OutStrength", ]
  
  outstrength_sorted <- outstrength_data[order(-outstrength_data$value), ]
  
  top_outstrength_nodes <- c(top_outstrength_nodes, outstrength_sorted$node[1])
  if (nrow(outstrength_sorted) >= 2) {
    second_outstrength_nodes <- c(second_outstrength_nodes, outstrength_sorted$node[2])
  }
  
  instrength_data <- file[file$measure == "InStrength", ]
  
  instrength_sorted <- instrength_data[order(-instrength_data$value), ]
  
  top_instrength_nodes <- c(top_instrength_nodes, instrength_sorted$node[1])
  if (nrow(instrength_sorted) >= 2) {
    second_instrength_nodes <- c(second_instrength_nodes, instrength_sorted$node[2])
  }
}

# Count the frequency of the strongest and the second strongest
outstrength_top_counts <- as.data.frame(table(top_outstrength_nodes))
second_outstrength_counts <- as.data.frame(table(second_outstrength_nodes))

instrength_top_counts <- as.data.frame(table(top_instrength_nodes))
second_instrength_counts <- as.data.frame(table(second_instrength_nodes))

colnames(outstrength_top_counts) <- c("Node", "OutStrength_Top_sd")
colnames(second_outstrength_counts) <- c("Node", "OutStrength_Second_sd")

colnames(instrength_top_counts) <- c("Node", "InStrength_Top_sd")
colnames(second_instrength_counts) <- c("Node", "InStrength_Second_sd")

# Combine OutStrength and InStrength
combined_outstrength_counts <- merge(outstrength_top_counts, second_outstrength_counts, by = "Node", all = TRUE)
combined_instrength_counts <- merge(instrength_top_counts, second_instrength_counts, by = "Node", all = TRUE)

# Combine OutStrength and InStrength into one table
combined_strength_counts_sds <- merge(combined_outstrength_counts, combined_instrength_counts, by = "Node", all = TRUE)

combined_strength_counts_sds[is.na(combined_strength_counts_sds)] <- 0

# Add percentages 
combined_strength_counts_sds$OutStrength_Top <- paste0(combined_strength_counts_sds$OutStrength_Top, " (", 
                                                     sprintf("%.2f", (combined_strength_counts_sds$OutStrength_Top / total_datasets) * 100), "%)")
combined_strength_counts_sds$OutStrength_Second <- paste0(combined_strength_counts_sds$OutStrength_Second, " (", 
                                                        sprintf("%.2f", (combined_strength_counts_sds$OutStrength_Second / total_datasets) * 100), "%)")

combined_strength_counts_sds$InStrength_Top <- paste0(combined_strength_counts_sds$InStrength_Top, " (", 
                                                    sprintf("%.2f", (combined_strength_counts_sds$InStrength_Top / total_datasets) * 100), "%)")
combined_strength_counts_sds$InStrength_Second <- paste0(combined_strength_counts_sds$InStrength_Second, " (", 
                                                       sprintf("%.2f", (combined_strength_counts_sds$InStrength_Second / total_datasets) * 100), "%)")

print(combined_strength_counts_sds)

write.csv(combined_strength_counts_sds, "Paper_res/New_tables/Top_2_out_and_in_strength_sds.csv")
```

```{r Means and SDs OutStrength and InStrength}
combined_strength_counts_all <- merge(combined_strength_counts_means, combined_strength_counts_sds, by = "Node", all = TRUE)

write.csv(combined_strength_counts_all, "Paper_res/New_tables/Top_2_out_and_in_strength_means_and_sds.csv")
```

```{r Break down feel_fat and fowg}
data_lst_means <- lapply(files_to_read, read.csv)

count_only_feelfat <- 0
count_only_fowg <- 0
count_both_nodes <- 0

for (df in data_lst_means) {
  
  has_feelfat <- any(df$node == "feelfat")
  has_fowg <- any(df$node == "fowg")
  
  
  if (has_feelfat && !has_fowg) {
    count_only_feelfat <- count_only_feelfat + 1
  } else if (!has_feelfat && has_fowg) {
    count_only_fowg <- count_only_fowg + 1
  } else if (has_feelfat && has_fowg) {
    count_both_nodes <- count_both_nodes + 1
  }
}

cat("Files with only Feeling Fat (no Fear of Weight Gain):", count_only_feelfat, "\n")
cat("Files with only Fear of Weight Gain (no Feeling Fat):", count_only_fowg, "\n")
cat("Files with both Feeling Fat and Fear of Weight Gain:", count_both_nodes, "\n")
```

```{r Break down sleep disurbances}
data_lst_means <- lapply(files_to_read, read.csv)

count_only_tired <- 0
count_only_sleep <- 0
count_both_nodes <- 0

for (df in data_lst_means) {
  
  has_tired <- any(df$node == "tired")
  has_sleep <- any(df$node == "sleep")
  
  
  if (has_tired && !has_sleep) {
    count_only_tired <- count_only_tired + 1
  } else if (!has_tired && has_sleep) {
    count_only_sleep <- count_only_sleep + 1
  } else if (has_tired && has_sleep) {
    count_both_nodes <- count_both_nodes + 1
  }
}

cat("Files with only Tired (no sleep):", count_only_tired, "\n")
cat("Files with only sleep (no Tired):", count_only_sleep, "\n")
cat("Files with both Tired and sleep:", count_both_nodes, "\n")
```

```{r Break down sleep disturbances by feel_fat and fowg}
# For participants with tiredness and fatigue and no low sleep, what is the breakdown of feel_fat and fowg?

filtered_data_lst_means <- list()
for (i in seq_along(data_lst_means)) {
  df <- data_lst_means[[i]]
  if ("tired" %in% df$node && !("sleep" %in% df$node)) {
    filtered_data_lst_means[[length(filtered_data_lst_means) + 1]] <- df
  }
}

count_only_feelfat <- 0
count_only_fowg <- 0
count_both_nodes <- 0

for (df in filtered_data_lst_means) {
  
  has_feelfat <- any(df$node == "feelfat")
  has_fowg <- any(df$node == "fowg")
  
  if (has_feelfat && !has_fowg) {
    count_only_feelfat <- count_only_feelfat + 1
  } else if (!has_feelfat && has_fowg) {
    count_only_fowg <- count_only_fowg + 1
  } else if (has_feelfat && has_fowg) {
    count_both_nodes <- count_both_nodes + 1
  }
}

cat("Files with 'tired' and no low sleep and only Feeling Fat (no Fear of Weight Gain):", count_only_feelfat, "\n")
cat("Files with 'tired' and no low sleep and only Fear of Weight Gain (no Feeling Fat):", count_only_fowg, "\n")
cat("Files with 'tired' and no low sleep and both Feeling Fat and Fear of Weight Gain:", count_both_nodes, "\n")

# For participants with low sleep quality, what is the breakdown of feel_fat and fowg?
filtered_data_lst_means <- list()
for (i in seq_along(data_lst_means)) {
  df <- data_lst_means[[i]]
  if ("sleep" %in% df$node) {
    filtered_data_lst_means[[length(filtered_data_lst_means) + 1]] <- df
  }
}

count_only_feelfat <- 0
count_only_fowg <- 0
count_both_nodes <- 0

for (df in filtered_data_lst_means) {
  
  has_feelfat <- any(df$node == "feelfat")
  has_fowg <- any(df$node == "fowg")
  
  if (has_feelfat && !has_fowg) {
    count_only_feelfat <- count_only_feelfat + 1
  } else if (!has_feelfat && has_fowg) {
    count_only_fowg <- count_only_fowg + 1
  } else if (has_feelfat && has_fowg) {
    count_both_nodes <- count_both_nodes + 1
  }
}

cat("Files with low sleep and only Feeling Fat (no Fear of Weight Gain):", count_only_feelfat, "\n")
cat("Files with low sleep and only Fear of Weight Gain (no Feeling Fat):", count_only_fowg, "\n")
cat("Files with low sleep and both Feeling Fat and Fear of Weight Gain:", count_both_nodes, "\n")
```

```{r Unique combination of nodes across networks}
# Means
all_combos <- list()
for (df in data_lst_means) {
  df_means <- df %>% filter(measure == "Strength")  
  split_data <- split(df_means, list(df_means$graph, df_means$type))
  for (subset in split_data) {
    if (nrow(subset) > 0) {
      nodes_sorted <- paste(sort(subset$node), collapse = " ")
      all_combos <- c(all_combos, nodes_sorted)
    }
  }
}

#  unique combinations of variables across participants
combo_counts <- data.frame(table(unlist(all_combos)))
colnames(combo_counts) <- c("Node Combination", "Count")
combo_counts # all unique

# Variability
all_combos <- list()
for (df in data_lst_sds) {
  df_means <- df %>% filter(measure == "Strength")  
  split_data <- split(df_means, list(df_means$graph, df_means$type))
  for (subset in split_data) {
    if (nrow(subset) > 0) {
      nodes_sorted <- paste(sort(subset$node), collapse = " ")
      all_combos <- c(all_combos, nodes_sorted)
    }
  }
}

#  unique combinations of variables across participants
combo_counts <- data.frame(table(unlist(all_combos)))
colnames(combo_counts) <- c("Node Combination", "Count")
combo_counts # all unique
```

```{r Frequent combination of nodes across networks}
# Means
co_occurrence_list <- list()

for (df in data_lst_means) {
  strength_data <- df %>% filter(measure == "Strength")
  nodes <- strength_data$node

  if (length(nodes) > 1) {
    node_pairs <- combn(nodes, 2)
    
    # Sort pairs to avoid duplicates 
    sorted_pairs <- apply(node_pairs, 2, function(x) paste(sort(x), collapse = "_"))
    
    co_occurrence_list <- c(co_occurrence_list, sorted_pairs)
  }
}

# Frequency of each symptom pair
co_occurrence_counts <- as.data.frame(table(unlist(co_occurrence_list)))
colnames(co_occurrence_counts) <- c("Node_Pair", "Frequency")
(co_occurrence_counts <- co_occurrence_counts[order(-co_occurrence_counts$Frequency), ])

# Variability
co_occurrence_list <- list()

for (df in data_lst_sds) {
  strength_data <- df %>% filter(measure == "Strength")
  nodes <- strength_data$node

  if (length(nodes) > 1) {
    node_pairs <- combn(nodes, 2)
    
    # Sort pairs to avoid duplicates 
    sorted_pairs <- apply(node_pairs, 2, function(x) paste(sort(x), collapse = "_"))
    
    co_occurrence_list <- c(co_occurrence_list, sorted_pairs)
  }
}

# frequency of each symptom pair
co_occurrence_counts <- as.data.frame(table(unlist(co_occurrence_list)))
colnames(co_occurrence_counts) <- c("Node_Pair", "Frequency")
(co_occurrence_counts <- co_occurrence_counts[order(-co_occurrence_counts$Frequency), ])
```

